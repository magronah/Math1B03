---
title: "Lecture Notes"
author: "Michael Agronah"
date: "2023-05-28"
output:
  html_document: default
  pdf_document: default
---
[information on vector spaces](vectorspace.html)

# Topic:  Adjoint of Matrices

## Introduction
The adjoint of a matrix is useful in many applications of linear algebra. The adjoint matrix, also known as the adjugate or classical adjoint, is connected to the concept of a matrix's inverse. In this lecture, we will look at the definition and properties of a matrix's adjoint, with an emphasis on 3x3 matrices.


## Definition
Let $A$ be a square matrix of order $n$. The adjoint of $A$, denoted as $\text{adj}(A)$ or $A^*$, is defined as the transpose of the cofactor matrix of $A$. The cofactor of an element $a_{ij}$ in $A$ is given by $C_{ij} = (-1)^{i+j}\det(M_{ij})$, where $M_{ij}$ is the $(n-1)\times(n-1)$ submatrix obtained by deleting the $i$-th row and $j$-th column of $A$. 

The adjoint matrix can be expressed as $\text{adj}(A) = [C_{ij}]^T$. In other words, the $(i,j)$-th entry of the adjoint matrix is the cofactor of the $(j,i)$-th entry of the original matrix.


<!-- Let $A$ be a 3x3 matrix with entries $a_{ij}$ for $1 \leq i,j \leq 3$. The adjoint of matrix $A$, denoted by $\text{adj}(A)$, is defined as the transpose of the cofactor matrix of $A$. The cofactor of the entry $a_{ij}$ is denoted by $C_{ij}$ and is defined as $(-1)^{i+j}$ times the determinant of the submatrix obtained by deleting the $i$th row and $j$th column of $A$. -->

## Illustration 2 x 2 matrices

Let's find the adjoint of the matrix $A = \begin{bmatrix} 2 & 3 \\ 1 & 4 \end{bmatrix}$.

\subsection{Step 1: Calculate the Cofactors}

The cofactors of matrix $A$ are obtained by taking the determinants of the 1x1 matrices formed by each element of $A$. Thus:

\[
C_{11} = (-1)^{1+1} \cdot \begin{vmatrix} 4 \end{vmatrix} = 4
\]
\[
C_{12} = (-1)^{1+2} \cdot \begin{vmatrix} 1 \end{vmatrix} = -1
\]
\[
C_{21} = (-1)^{2+1} \cdot \begin{vmatrix} 3 \end{vmatrix} = -3
\]
\[
C_{22} = (-1)^{2+2} \cdot \begin{vmatrix} 2 \end{vmatrix} = 2
\]

Thus, the cofactor matrix $\text{cof}(A)$ is:

\[
\begin{bmatrix} 4 & -1 \\ -3 & 2 \end{bmatrix}
\]

\subsection{Step 2: Transpose the Cofactor Matrix}

The adjoint of matrix $A$ is obtained by taking the transpose of the cofactor matrix $\text{cof}(A)$. Thus, the adjoint $A^*$ is:

\[
A^* = \begin{bmatrix} 4 & -3 \\ -1 & 2 \end{bmatrix}
\]


## Illustration  3 x 3 matrices

Let's consider a 3x3 matrix $A$:

\[
A = \begin{bmatrix}
    a_{11} & a_{12} & a_{13} \\
    a_{21} & a_{22} & a_{23} \\
    a_{31} & a_{32} & a_{33} \\
\end{bmatrix}
\]

We can find the cofactor matrix of $A$ by computing the cofactors of each element:

\[
\text{cof}(A) = \begin{bmatrix}
    C_{11} & C_{12} & C_{13} \\
    C_{21} & C_{22} & C_{23} \\
    C_{31} & C_{32} & C_{33} \\
\end{bmatrix}
\]

where,

\[
C_{ij} = (-1)^{i+j}\det(M_{ij})
\]

and $M_{ij}$ is the $(2\times2)$ submatrix obtained by deleting the $i$-th row and $j$-th column of $A$.

Finally, we take the transpose of the cofactor matrix to obtain the adjoint of $A$:

\[
\text{adj}(A) = \begin{bmatrix}
    C_{11} & C_{21} & C_{31} \\
    C_{12} & C_{22} & C_{32} \\
    C_{13} & C_{23} & C_{33} \\
\end{bmatrix}^T
\]



## Example
Let's find the adjoint of the following matrix:
\[
A = \begin{bmatrix}
    2 & 3 & -1 \\
    0 & 4 & 2 \\
    1 & -3 & 5 \\
\end{bmatrix}
\]

To find the cofactor matrix, we calculate the cofactor for each entry of matrix $A$:
\[
C_{11} = (-1)^{1+1} \begin{vmatrix}
    4 & 2 \\
    -3 & 5 \\
\end{vmatrix} = 26
\]

\[
C_{12} = (-1)^{1+2} \begin{vmatrix}
    0 & 2 \\
    1 & 5 \\
\end{vmatrix} = 2
\]

\[
C_{13} = (-1)^{1+3} \begin{vmatrix}
    0 & 4 \\
    1 & -3 \\
\end{vmatrix} = -4
\]

\[
C_{21} = (-1)^{2+1} \begin{vmatrix}
    3 & -1 \\
    -3 & 5 \\
\end{vmatrix} = -12
\]

\[
C_{22} = (-1)^{2+2} \begin{vmatrix}
    2 & -1 \\
    1 & 5 \\
\end{vmatrix} = 11
\]

\[
C_{23} = (-1)^{2+3} \begin{vmatrix}
    2 & 3 \\
    1 & -3 \\
\end{vmatrix} = 9
\]

\[
C_{31} = (-1)^{3+1} \begin{vmatrix}
    3 & -1 \\
    4 & 2 \\
\end{vmatrix} = 10
\]

\[
C_{32} = (-1)^{3+2} \begin{vmatrix}
    2 & -1 \\
    0 & 2 \\
\end{vmatrix} = -4
\]

\[
C_{33} = (-1)^{3+3} \begin{vmatrix}
    2 & 3 \\
    0 & 4 \\
\end{vmatrix} = 8
\]

The cofactor matrix is given by:
\[
\text{cof}(A) = \begin{bmatrix}
    26 & 2 & -4 \\
    -12 & 11 & 9 \\
    10 & -4 & 8 \\
\end{bmatrix}
\]

Finally, we take the transpose of the cofactor matrix to obtain the adjoint of matrix $A$:
\[
\text{adj}(A) = \begin{bmatrix}
    26 & -12 & 10 \\
    2 & 11 & -4 \\
    -4 & 9 & 8 \\
\end{bmatrix}
\]

## Properties of the Adjoint
The adjoint of a matrix has several properties:

1. If $A$ is an invertible matrix, then $\text{adj}(A)$ is also invertible, and $(\text{adj}(A))^{-1} = \frac{1}{\det(A)}A$.

2. If $A$ is a symmetric matrix, then $\text{adj}(A) = A$.
3. If $A$ and $B$ are matrices of the same size, then $\text{adj}(AB) = \text{adj}(B) \cdot \text{adj}(A)$.

<!-- # Properties -->

<!-- The adjoint of a matrix has several important properties: -->

<!-- \begin{itemize} -->
<!--     \item If $A$ is invertible, then $\text{adj}(A)$ is given by $\text{adj}(A) = \frac{1}{\det(A)}\text{cof}(A)$. -->
<!--     \item The product of a matrix $A$ and its adjoint $\text{adj}(A)$ is a scalar multiple of the determinant of $A$: $A\cdot \text{adj}(A) = \det(A)I$, where $I$ is the identity matrix. -->
<!--     \item If $A$ is invertible, then $A^{-1} = \frac{1}{\det(A)}\text{adj}(A)$. -->
<!-- \end{itemize} -->


## Conclusion
A matrix's adjoint contains useful information about the original matrix, such as its invertibility and the relationship between the matrix and its determinant. We focused on the definition and properties of the adjoint of 2x2 and 3x3 matrices in this lesson. However, the adjoint idea can be used to matrices of any order. Further study of this subject will broaden your grasp of linear algebra and its applications. 


# Topic:  Vector Spaces and Subspaces

## Introduction

Today's lecture is about vector spaces and subspaces. Vector spaces play a very important foundation for understanding many essential concepts in linear algebra such as linear transformations, eigenvectors.  The essential ideas, properties, and examples of vector spaces and subspaces will be discussed in this lecture.

## Vector Spaces
A vector space $V$ is a collection of vectors that satisfy specific criteria. 

### Definition: 
A vector space $V$ over a field $F$ is a set of vectors (note: non-empty set of vectors) with two operations namely

1. Vector Addition: For any two vectors $u$ and $v$ $\in V$, there exists a unique vector $u + v$,  also in $V$.
2. Scalar Multiplication: For any vector $u \in V$ and any scalar $c in F$, there exists a unique vector $cu$, also in $V$.


These 2 operations mentioned above must satisfy the following 10 properties. Lets list the properties. 

For all vectors $u, v$, and $w \in V$ and scalars $c$ and $d \in F$:

1. $u + v \in V$ (Closure under addition)
2. $cv \in V$ (Closure under scalar multiplication )
3. $u + v = v + u$ (Commutativity of Addition)
4. $(u + v) + w = u + (v + w)$ (Associativity of Addition)
5. There exists a vector $0 \in V$ such that $u + 0 = u$ (Identity Element of Addition)
6. For any vector $u \in V$, there exists a vector $-u \in V$ such that $u + (-u) = 0$ (Inverse Elements of Addition)
7. $c(du) = (cd)u$ (Compatibility of Scalar Multiplication with Field Multiplication)
8. $1u = u$, (1 is the multiplicative identity in $F$)
9. $c(u + v) = cu + cv$ (Distributivity of Scalar Multiplication with respect to Vector Addition)
10. $(c + d)u = cu + du$ (Distributivity of Scalar Multiplication with respect to Field Addition)
 
## Example: 
The n-dimensional space $R^n$ is a vector space.

1.\textbf{1. Closure under addition:} For any $\mathbf{u}, \mathbf{v} \in V$, $\mathbf{u} + \mathbf{v} \in R^n$. This is true because in an n-dimensional space, adding two vectors results in another vector within the same space.

2.\textbf{2. Closure under scalar multiplication:} For any $\mathbf{u} \in V$ and scalar $c$, $c\mathbf{u} \in R^n$. This holds true as multiplying a vector by a scalar does not change the dimensionality of the vector space.

3.\textbf{3. Commutativity of addition:} For any $\mathbf{u}, \mathbf{v} \in V$, $\mathbf{u} + \mathbf{v} = \mathbf{v} + \mathbf{u}$. This property follows from the commutative property of addition in the underlying field.

4.\textbf{4. Associativity of addition:} For any $\mathbf{u}, \mathbf{v}, \mathbf{w} \in R^n$, $(\mathbf{u} + \mathbf{v}) + \mathbf{w} = \mathbf{u} + (\mathbf{v} + \mathbf{w})$. This property follows from the associativity of addition in the underlying field.

5.\textbf{5. Existence of zero vector:} There exists a vector $\mathbf{0} \in R^n$ such that for any $\mathbf{u} \in V$, $\mathbf{u} + \mathbf{0} = \mathbf{u}$. This vector $\mathbf{0}$ is the additive identity element in the underlying field.

6.\textbf{6. Existence of additive inverse:} For any $\mathbf{u} \in V$, there exists a vector $-\mathbf{u} \in V$ such that $\mathbf{u} + (-\mathbf{u}) = \mathbf{0}$. This property ensures that every vector has an additive inverse.

7.\textbf{7. Distributivity of scalar multiplication over vector addition:} For any scalars $a$ and $b$ and $\mathbf{u} \in V$, $(a + b)\mathbf{u} = a\mathbf{u} + b\mathbf{u}$. This property follows from the distributivity of scalar multiplication over addition in the underlying field.

8.\textbf{8. Distributivity of scalar multiplication over field addition:} For any scalar $a$ and vectors $\mathbf{u}, \mathbf{v} \in V$, $a(\mathbf{u} + \mathbf{v}) = a\mathbf{u} + a\mathbf{v}$. This property follows from the distributivity of scalar multiplication over addition in the underlying field.

9.\textbf{9. Compatibility of scalar multiplication with field multiplication:} For any scalars $a$ and $b$ and $\mathbf{u} \in V$, $(ab)\mathbf{u} = a(b\mathbf{u})$. This property follows from the associativity of multiplication in the underlying field.

10.\textbf{10. }   1$\mathbf{u} = u\in R^n$

Since all the vector space axioms hold for the n-dimensional space $R^n$, it is indeed a vector space.

